# Optimization Rush
 **Цель** - максимально эффективно обучить LLM, используя все доступные методы оптимизации
## Методы
1. Оптимизация всегда должна начинаться в первую очередь с **выбора модели**. Если ваша задача не является комплексной, то модель с несколькими миллиардами параметров сможет справиться с ней почти так же хорошо, как какой-нибуль гигант на несколько сотен миллиардов параметров.
    - Я мог бы вместить Llama-3-70B на A100 и пофайнтюнить ее, а для инференса можно было бы даже засунуть ее на одну T4 с cpu/disk offload. Но я посчитал, что для генерации небольших рецептов вполне хватит версии на 8B.
2. **Качество датасета намного важнее его количества.** Хорошо подготовленный датасет, который в 10 раз меньше около рандомного скрапинга, даст качество зачастую даже лучше. И, главное, само обучение будет в 10 раз быстрее. Только придется потратить больше времени на обработку датасета.
    - Я очень сильно почистил датасет. Изначально в нем было 2M рецептов. Я убрал очень короткие/длинные рецепты, рецепты с очень большим/маленьким набором ингридиентов, и убрал рецепты, в которых встречались очень редкие ингридиенты. Всё это позволило мне сократить датасет в более чем два раза, убрать очень много мусора, оставить более качественные рецепты, которые будут давать более сильный сигнал.
3. **Sequence packing.** Все мы знаем, что последовательности бывают разной длины, поэтому приходится делать паддинг. Это самое простое, но самое неэффективное решение по упаковке и отправке данных в модель. Из-за паддинга около половины (зависит от разброса длин в датасете) вычислений проходят в пустую. Существует много способов и связанных с ними трудностей по эффективной упаковке батчей. Отсылаю вас к этому небольшому, но вполне исчерпывающему посту https://lweitkamp.github.io/posts/packing/#fn2
    - Так как я не хотел смешивать в одной последовательности несколько рецептов и обрезать конец, что очень часто приводило бы к бессмысленным неоконченным рецептам, я выбрал стратегию сортировки. То есть, отсортировал датасет по длине последовательности, нарезал этот датасет на батчи, потом перемешал порядок батчей. Благодаря этому минимизируется количество паддингов в батче.
4. **PEFT (Parameter-Efficient Fine-Tuning).** Lora..........
5. **Quantization.**
6. **Mixed Precision**
7. **8-bit optimizers**
8. **torch.compile**
9. **Efficient attention**
10. **Efficient DataLoader**
11. **Gradient Checkpointing**
12. **Gradient Accumulation**
