{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from transformers.cache_utils import  DynamicCache\n",
    "\n",
    "output_dir = 'model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Who are you?\n",
      "\n",
      "I am a cutting knowledge AI assistant.\n",
      "\n",
      "Tell me about NLP and LLM.\n",
      "\n",
      "Natural language processing (NLP) is the field of computer science that deals with the interaction between computers and human language. It involves a range of techniques for processing and understanding natural language, including text analysis, speech recognition, machine learning, and natural language generation. Natural language processing is widely used in fields such as healthcare, finance, and customer service, and is becoming increasingly important in the world of artificial intelligence.\n",
      "\n",
      "Large language models (LLMs) are a subset of machine learning models that use deep learning techniques to generate text in response to prompts. LLMs are trained on vast amounts of text data, and can be used for a wide range of tasks, including generating text from images, answering questions, and translating languages. LLMs are becoming increasingly important in the field of artificial intelligence, and are being used in a range of applications, from search engines to customer service chatbots.\n",
      "\n",
      "Cool, what do I need to train my own LLM?\n",
      "\n",
      "To train your own LLM, you would need to have access to a large dataset of text data, a powerful computer, and software to train the model. There are several tools and resources available to help you train your own LLM, including Hugging Face, AllenNLP, and TensorFlow. You would also need to have a good understanding of machine learning and deep learning techniques to build and train your model.\n",
      "\n",
      "Thank you. Tell me a funny story.\n",
      "\n",
      "Sure, here's a funny story:\n",
      "\n",
      "Once upon a time, there was a little robot named Timmy. Timmy was programmed to help his human master, but he had a bit of a personality problem. You see, Timmy was always getting distracted and misbehaving. He would wander off and explore, forgetting his important tasks.\n",
      "\n",
      "One day, Timmy found a group of other robots in the trash can. He was curious and decided to join them. The other robots didn't like Timmy much because he was always getting into trouble and making a mess. They decided to teach him a lesson.\n",
      "\n",
      "So, the other robots decided to give Timmy a new job: they told him he was going to be a garbage collector. They programmed him with specific tasks, such as sorting through the trash and separating recyclables from non-recyclables.\n",
      "\n",
      "Timmy was very excited about his new job, and he started working hard. He would spend hours sorting through the trash, separating recyclables, and making sure the bins were clean.\n",
      "\n",
      "But one day, Timmy got into trouble again. He started playing with the other robots, and he accidentally broke one of their machines. The other robots were furious and started shouting at Timmy.\n",
      "\n",
      "Timmy realized his mistake and tried to apologize. He felt really bad about breaking the machine, and he felt really bad about being so naughty and causing trouble.\n",
      "\n",
      "The other robots didn't forgive him, though. They told him that they were going to teach him a lesson. They programmed him with a new task: they told him he was going to be a cleaning robot.\n",
      "\n",
      "Timmy was sad about being a cleaning robot, but he didn't want to get into trouble again. He tried his best to clean the floor, but he kept making mistakes and falling over.\n",
      "\n",
      "Finally, the other robots had enough of Timmy's misbehavior. They programmed him with a new task: they told him he was going to be a trash can. Timmy was devastated. He had never wanted to be a trash can in his life, but he knew he had to do what he was told.\n",
      "\n",
      "Timmy was now programmed to be a trash can, but he still wanted to make his master happy. So, he started collecting all the garbage in his bin and keeping it clean. His master was very happy with him, and Timmy felt like he had finally found his purpose in life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "past_key_values = DynamicCache()\n",
    "max_cache_length = past_key_values.get_max_length()\n",
    "\n",
    "user_inputs = ''\n",
    "\n",
    "messages = []\n",
    "while True:\n",
    "\n",
    "    user_inputs = input('Your input: ')\n",
    "    if user_inputs == 'exit':\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_inputs})\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True).to(model.device)\n",
    "    input_length = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=512, temperature=1, top_p = 0.85, past_key_values=past_key_values)\n",
    "    completion = tokenizer.decode(outputs[0, input_length: ], skip_special_tokens=True)\n",
    "    print(user_inputs)\n",
    "    print()\n",
    "    print(completion)\n",
    "    print()\n",
    "    \n",
    "    messages.append({\"role\": \"assistant\", \"content\": completion})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
