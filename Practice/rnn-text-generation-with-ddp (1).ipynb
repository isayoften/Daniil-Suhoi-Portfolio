{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:12:54.318959Z","iopub.execute_input":"2024-05-15T15:12:54.319614Z","iopub.status.idle":"2024-05-15T15:12:54.324365Z","shell.execute_reply.started":"2024-05-15T15:12:54.319577Z","shell.execute_reply":"2024-05-15T15:12:54.323393Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport random\nimport torchmetrics\nimport torch.nn.functional as F\n\nfrom accelerate import Accelerator\nfrom accelerate.utils import set_seed\nfrom accelerate import notebook_launcher\n# import evaluate\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\n\nfrom collections import Counter\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:12:54.327433Z","iopub.execute_input":"2024-05-15T15:12:54.327743Z","iopub.status.idle":"2024-05-15T15:13:00.714205Z","shell.execute_reply.started":"2024-05-15T15:12:54.327717Z","shell.execute_reply":"2024-05-15T15:13:00.713187Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"id":"91JuM0SQvXud","execution":{"iopub.status.busy":"2024-05-15T15:13:00.716332Z","iopub.execute_input":"2024-05-15T15:13:00.717263Z","iopub.status.idle":"2024-05-15T15:13:00.798123Z","shell.execute_reply.started":"2024-05-15T15:13:00.717211Z","shell.execute_reply":"2024-05-15T15:13:00.797180Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset('imdb')","metadata":{"id":"qHLNWOfJqSfc","execution":{"iopub.status.busy":"2024-05-15T15:13:00.799280Z","iopub.execute_input":"2024-05-15T15:13:00.799567Z","iopub.status.idle":"2024-05-15T15:13:07.978826Z","shell.execute_reply.started":"2024-05-15T15:13:00.799543Z","shell.execute_reply":"2024-05-15T15:13:07.978014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sentences = []\nsentence_len_treshold = 256\n\nfor review in tqdm(dataset['unsupervised']['text']):\n    sentences.extend([x.lower() for x in sent_tokenize(review) if len(x)<sentence_len_treshold])","metadata":{"id":"Ins2tVCdsS47","execution":{"iopub.status.busy":"2024-05-15T15:13:07.981157Z","iopub.execute_input":"2024-05-15T15:13:07.981479Z","iopub.status.idle":"2024-05-15T15:13:35.982710Z","shell.execute_reply.started":"2024-05-15T15:13:07.981454Z","shell.execute_reply":"2024-05-15T15:13:35.981704Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:27<00:00, 1796.40it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(sentences))","metadata":{"id":"bxeBxP3J1Rj3","execution":{"iopub.status.busy":"2024-05-15T15:13:35.983942Z","iopub.execute_input":"2024-05-15T15:13:35.984265Z","iopub.status.idle":"2024-05-15T15:13:35.989127Z","shell.execute_reply.started":"2024-05-15T15:13:35.984220Z","shell.execute_reply":"2024-05-15T15:13:35.988226Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"493165\n","output_type":"stream"}]},{"cell_type":"code","source":"words = Counter()\n\nfor sentence in tqdm(sentences):\n    for word in word_tokenize(sentence):\n        words[word] += 1\n","metadata":{"id":"nEvCN0Y1w1yH","execution":{"iopub.status.busy":"2024-05-15T15:13:35.990206Z","iopub.execute_input":"2024-05-15T15:13:35.990498Z","iopub.status.idle":"2024-05-15T15:15:36.226910Z","shell.execute_reply.started":"2024-05-15T15:13:35.990475Z","shell.execute_reply":"2024-05-15T15:15:36.225941Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 493165/493165 [02:00<00:00, 4102.04it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(words)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:36.228154Z","iopub.execute_input":"2024-05-15T15:15:36.228483Z","iopub.status.idle":"2024-05-15T15:15:36.235164Z","shell.execute_reply.started":"2024-05-15T15:15:36.228449Z","shell.execute_reply":"2024-05-15T15:15:36.234099Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"135739"},"metadata":{}}]},{"cell_type":"code","source":"vocab = set(['<bos>','<eos>','<pad>','<unk>'])\nword_count_threshold = 75\n\n\n\nfor word, count in words.items():\n    if count > word_count_threshold:\n        vocab.add(word)\n\n        \nprint(len(vocab))","metadata":{"id":"oUBNwsK9xLIu","execution":{"iopub.status.busy":"2024-05-15T15:15:36.236310Z","iopub.execute_input":"2024-05-15T15:15:36.236600Z","iopub.status.idle":"2024-05-15T15:15:36.290905Z","shell.execute_reply.started":"2024-05-15T15:15:36.236573Z","shell.execute_reply":"2024-05-15T15:15:36.289940Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"6972\n","output_type":"stream"}]},{"cell_type":"code","source":"word2ind = {char: i for i, char in enumerate(vocab)}\nind2word = {i: char for char, i in word2ind.items()}","metadata":{"id":"iD7SmSy3v2dl","execution":{"iopub.status.busy":"2024-05-15T15:15:36.292238Z","iopub.execute_input":"2024-05-15T15:15:36.292701Z","iopub.status.idle":"2024-05-15T15:15:36.300712Z","shell.execute_reply.started":"2024-05-15T15:15:36.292659Z","shell.execute_reply":"2024-05-15T15:15:36.299660Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class WordDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = word2ind['<unk>']\n        self.bos_id = word2ind['<bos>']\n        self.eos_id = word2ind['<eos>']\n        self.pad_id = word2ind['<pad>']\n\n    def __getitem__(self, idx):\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [word2ind.get(word, self.unk_id) for word in word_tokenize(self.data[idx])]\n        tokenized_sentence += [self.eos_id]\n#         tokenized_sentence += [self.pad_id]*(max_len-len(tokenized_sentence))\n\n        return torch.LongTensor(tokenized_sentence)\n\n    def __len__(self):\n        return len(self.data)","metadata":{"id":"FVzXL17PzC7K","execution":{"iopub.status.busy":"2024-05-15T15:24:42.524208Z","iopub.execute_input":"2024-05-15T15:24:42.524669Z","iopub.status.idle":"2024-05-15T15:24:42.533345Z","shell.execute_reply.started":"2024-05-15T15:24:42.524636Z","shell.execute_reply":"2024-05-15T15:24:42.532037Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\ndef collate_fn(batch):\n    lens = [len(x) for x in batch]\n    \n    padded_seq = pad_sequence(sequences=batch, batch_first=True, padding_value=word2ind['<pad>'])\n    \n#     padded_seq = accelerator.pad_across_processes(sequences=batch, dim=1, pad_index=word2ind['<pad>'])\n    \n    return padded_seq,  torch.LongTensor(lens)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:36.312692Z","iopub.execute_input":"2024-05-15T15:15:36.313014Z","iopub.status.idle":"2024-05-15T15:15:36.325344Z","shell.execute_reply.started":"2024-05-15T15:15:36.312983Z","shell.execute_reply":"2024-05-15T15:15:36.324557Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass RNN(nn.Module):\n    def __init__( self,  vocab_size, hidden_dim=256, embed_dim=512):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, )\n        self.rnn = nn.LSTM(input_size=embed_dim, \n                           hidden_size=hidden_dim, \n                           num_layers=3, \n                           batch_first=True,\n                           dropout=0.1)\n        \n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, vocab_size)\n        )\n        \n\n    def forward(self, x, lens):\n        embeddings = self.embedding(x)\n        embeddings = pack_padded_sequence(embeddings,lens.cpu(), batch_first=True, enforce_sorted=False)\n        output, (_,_) = self.rnn(embeddings) \n        output, _ = pad_packed_sequence(output,batch_first=True)\n        output = self.fc(output)\n        \n        loss = F.cross_entropy(output[:, :-1, :].flatten(start_dim=0, end_dim=1),x[:, 1:].flatten(),ignore_index=word2ind['<pad>'])\n        \n        return output, loss","metadata":{"id":"qaWvqNJom0ij","execution":{"iopub.status.busy":"2024-05-15T15:18:14.679935Z","iopub.execute_input":"2024-05-15T15:18:14.680568Z","iopub.status.idle":"2024-05-15T15:18:14.690553Z","shell.execute_reply.started":"2024-05-15T15:18:14.680529Z","shell.execute_reply":"2024-05-15T15:18:14.689628Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_dataloaders(batch_size = 64):\n    train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, shuffle=True, random_state=42)\n\n    train_dataset = WordDataset(train_sentences)\n    test_dataset = WordDataset(test_sentences)\n\n    train_dataloader = DataLoader(\n        train_dataset, collate_fn=collate_fn, batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n\n    test_dataloader = DataLoader(\n        test_dataset, collate_fn=collate_fn, batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True, shuffle=False)\n    \n    return train_dataloader, test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:36.339297Z","iopub.execute_input":"2024-05-15T15:15:36.339585Z","iopub.status.idle":"2024-05-15T15:15:36.352218Z","shell.execute_reply.started":"2024-05-15T15:15:36.339562Z","shell.execute_reply":"2024-05-15T15:15:36.351389Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def training_loop(mixed_precision=\"fp16\", seed = 42, checkpoint_path = None):\n    set_seed(seed)\n    accelerator = Accelerator(mixed_precision=mixed_precision)\n    \n    train_dataloader, test_dataloader = get_dataloaders(128)\n    model = RNN(vocab_size=len(vocab))\n\n    optim = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=3, factor=0.5)\n    \n    \n    model, optim, train_dataloader, test_dataloader, scheduler = accelerator.prepare(\n        model, optim, train_dataloader, test_dataloader, scheduler\n    )\n    \n    resume_epoch = 0\n    \n    if checkpoint_path is not None:\n        accelerator.wait_for_everyone()\n        accelerator.load_state(checkpoint_path)\n        resume_epoch = int(checkpoint_path.split(\"_\")[-1])+1\n\n\n        \n    for epoch in range(resume_epoch, 300):\n    \n        train_total_loss = 0\n        model.train()\n        loop = tqdm(train_dataloader, disable=not accelerator.is_local_main_process)\n        for X, lens in loop:\n            with accelerator.autocast():\n                logits, loss = model(X, lens)\n\n            optim.zero_grad(set_to_none=True)\n            accelerator.backward(loss)\n            optim.step()\n\n            train_total_loss += loss\n            \n\n        train_total_loss = (accelerator.gather(train_total_loss)/len(train_dataloader)).sum()/2\n\n        test_total_loss = 0\n\n        model.eval()\n        with torch.inference_mode():\n            loop = tqdm(test_dataloader, disable=not accelerator.is_local_main_process)\n            for X, lens in loop:\n                logits, loss = model(X, lens)           \n\n                test_total_loss += loss\n                \n\n            test_total_loss = (accelerator.gather(test_total_loss)/len(test_dataloader)).sum()/2\n\n            \n        scheduler.step(test_total_loss)\n        accelerator.print(f\"epoch: {epoch}   train_loss: {train_total_loss}, test_loss: {test_total_loss}\")\n        \n        \n        accelerator.wait_for_everyone()\n        accelerator.save_state(f\"/kaggle/working/cp_{epoch}\", safe_serialization=False)\n        \n        \n        \n#         if accelerator.is_local_main_process:\n#             torch.save(accelerator.unwrap_model(model).state_dict(), f'/kaggle/working/cp_{epoch}.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:18:19.171430Z","iopub.execute_input":"2024-05-15T15:18:19.171815Z","iopub.status.idle":"2024-05-15T15:18:19.184744Z","shell.execute_reply.started":"2024-05-15T15:18:19.171787Z","shell.execute_reply":"2024-05-15T15:18:19.183619Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"args = (\"fp16\", 42, None)\nnotebook_launcher(training_loop, args, num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:18:21.164952Z","iopub.execute_input":"2024-05-15T15:18:21.165329Z","iopub.status.idle":"2024-05-15T15:20:01.631664Z","shell.execute_reply.started":"2024-05-15T15:18:21.165300Z","shell.execute_reply":"2024-05-15T15:20:01.630203Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Launching training on 2 GPUs.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1542/1542 [01:21<00:00, 18.86it/s]\n100%|██████████| 386/386 [00:12<00:00, 30.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0   train_loss: 4.675525665283203, test_loss: 4.21187162399292\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 43/1542 [00:02<01:34, 15.79it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/launchers.py:201\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_processes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlauncher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:202\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:114\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# model = RNN(vocab_size=len(vocab))\n# model.load_state_dict(torch.load(\"/kaggle/working/cp_7.pt\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:40.946102Z","iopub.status.idle":"2024-05-15T15:15:40.946625Z","shell.execute_reply.started":"2024-05-15T15:15:40.946364Z","shell.execute_reply":"2024-05-15T15:15:40.946386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_sequence(model, starting_seq: str, max_seq_len: int = 128):\n#     device = 'cpu'\n#     model = model.to(device)\n#     input_ids = [word2ind['<bos>']] + [\n#         word2ind.get(word, word2ind['<unk>']) for word in word_tokenize(starting_seq)]\n#     input_ids = torch.LongTensor(input_ids).to(device)\n#     model.eval()\n#     with torch.no_grad():\n#         for i in range(max_seq_len):\n#             next_char_distribution = model(input_ids)[-1]\n#             next_char = next_char_distribution.argmax()\n#             input_ids = torch.cat([input_ids, next_char.unsqueeze(0)])\n\n#             if next_char.item() == word2ind['<eos>']:\n#                 break\n    \n#     words = ' '.join([ind2word[idx.item()] for idx in input_ids])\n\n#     return words","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:40.948152Z","iopub.status.idle":"2024-05-15T15:15:40.948587Z","shell.execute_reply.started":"2024-05-15T15:15:40.948413Z","shell.execute_reply":"2024-05-15T15:15:40.948429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate_sequence(model, starting_seq='this movie was')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T15:15:40.949901Z","iopub.status.idle":"2024-05-15T15:15:40.950298Z","shell.execute_reply.started":"2024-05-15T15:15:40.950110Z","shell.execute_reply":"2024-05-15T15:15:40.950125Z"},"trusted":true},"execution_count":null,"outputs":[]}]}